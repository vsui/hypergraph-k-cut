# hexperiment

This is a tool for generating benchmark data for the various hypergraph cut algorithms.

Generally, this tool will generate families of hypergraphs and run cut algorithms on each hypergraph instance.
At the end of the run the tool will output information on the runs into an output folder.

## Usage

```hexperiment <config> <dest>```

`<config>` is a path to a YAML file for the configuration of the experiment.
For examples of valid config files see the [`config` directory](config).

`dest` is a path to an output directory for the artifacts generated by a run of `hexperiment`.

### Discovery experiments

Discovery experiments measure the time needed for an algorithm to discover a planted minimum cut. It produces
the following artifacts:

- `data.db`: a SQLite database containing individual runs of the algorithm as well as hypergraphs and cuts
- `data.csv`: A CSV file containing averages for the run times of each algorithm on each hypergraph
- `log.txt`: A log of the experiment
- `config.yaml`: The config file of the experiment
- Various plots

### Cutoff experiments

Cutoff experiments give contraction algorithms a time limit and tracks how close each contraction algorithm
gets to the minimum cut at different percentages of the time that an ordering-based algorithm needs. It
produces the following artifacts:

- `data.db`: A SQLite database
- A plot for each hypergraph of cutoff percentage vs. cut factor (found cut / minimum cut)

## Utilities

You may want to check the sizes of all the hypergraphs generated by a specific configuration before running
an experiment.
You can do this with the `-s` flag:

```hexperiment <config> -s```

For experiments with non-planted instances, you may want to check that the hypergraphs all have interesting cuts.
You can do this with the `-c` flag:

```hexperiment <config> -c```

Note that the experiment runner will automatically discard instances with uninteresting cuts.
